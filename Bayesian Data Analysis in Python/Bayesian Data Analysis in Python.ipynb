{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6908981c-2b08-4323-bf46-46394f495728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bayesian Data Analysis in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1099e-5a05-4146-8379-6fca0d1763f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the list of draws\n",
    "print(draws)\n",
    "\n",
    "# Print the length of draws\n",
    "print(len(draws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14992bcd-6be0-4ae3-98f1-9292f8acd2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of draws\n",
    "print(draws)\n",
    "\n",
    "# Print the length of draws\n",
    "print(len(draws))\n",
    "\n",
    "# Plot the density of draws\n",
    "sns.kdeplot(draws, fill=True, shade=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc3dc2-d165-4b31-abd3-d94820c241d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of drawing a king or queen\n",
    "p_king_or_queen = (4 + 4) / 52\n",
    "\n",
    "# Print the probability\n",
    "print(p_king_or_queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29117669-23e2-422d-a553-4cebd86bddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of drawing <= 5\n",
    "p_five_or_less = 16 / 52\n",
    "\n",
    "# Print the probability\n",
    "print(p_five_or_less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67457111-08a5-409a-ad19-d82191868d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of drawing four aces\n",
    "p_all_four_aces = (4 / 52) * (3 / 51) * (2 / 50) * (1 / 49)\n",
    "\n",
    "# Print the probability\n",
    "print(p_all_four_aces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06199987-8fe7-452c-b0b2-742fcdd91008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the unconditional probability of spam\n",
    "p_spam = emails['spam'].mean()\n",
    "print(p_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79b354-3625-4f82-873e-906eafe30b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the unconditional probability of spam\n",
    "p_spam = emails[\"spam\"].mean()\n",
    "print(p_spam)\n",
    "\n",
    "# Calculate and print the unconditional probability of \"!!!\"\n",
    "p_3_excl = emails['contains_3_excl'].mean()\n",
    "print(p_3_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af5bab-d787-4905-9453-1ae185988177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the unconditional probability of spam\n",
    "p_spam = emails[\"spam\"].mean()\n",
    "print(p_spam)\n",
    "\n",
    "# Calculate and print the unconditional probability of \"!!!\"\n",
    "p_3_excl = emails[\"contains_3_excl\"].mean()\n",
    "print(p_3_excl)\n",
    "\n",
    "# Calculate and print the probability of \"!!!\" given spam\n",
    "p_3_excl_given_spam = emails[emails['spam']]['contains_3_excl'].mean()\n",
    "print(p_3_excl_given_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc3a1f-989f-4f76-84a9-20cf7c6411b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the unconditional probability of spam\n",
    "p_spam = emails[\"spam\"].mean()\n",
    "print(p_spam)\n",
    "\n",
    "# Calculate and print the unconditional probability of \"!!!\"\n",
    "p_3_excl = emails[\"contains_3_excl\"].mean()\n",
    "print(p_3_excl)\n",
    "\n",
    "# Calculate and print the probability of \"!!!\" given spam\n",
    "p_3_excl_given_spam = emails.loc[emails[\"spam\"]][\"contains_3_excl\"].mean()\n",
    "print(p_3_excl_given_spam)\n",
    "\n",
    "# Calculate and print the probability of spam given \"!!!\"\n",
    "p_spam_given_3_excl = (p_3_excl_given_spam * p_spam) / p_3_excl\n",
    "print(p_spam_given_3_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea0a7e-906d-4fd5-8ae7-c4c948e5d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 coin tosses with a 50% chance of heads\n",
    "tosses = np.random.binomial(1, 0.5, size=1000)\n",
    "\n",
    "# Estimate the heads probability using the custom function\n",
    "heads_prob = get_heads_prob(tosses)\n",
    "\n",
    "# Plot the distribution of heads probability\n",
    "sns.kdeplot(heads_prob, shade=True, label='heads probabilty')  # Fix the label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d26d45-d16f-4a6b-a7b1-bdae8b96411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate and plot heads probability based on no data\n",
    "heads_prob_nodata = get_heads_prob([])\n",
    "\n",
    "# Plot the distribution of heads probability with no data\n",
    "sns.kdeplot(data=[heads_prob_nodata], shade=True, label=\"no data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f6ae0-ed8a-4382-8a1a-dc0f91e940ba",
   "metadata": {},
   "source": [
    "### The more you toss, the more you learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e7385-c542-4d77-9346-3755fc92fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate and plot heads probability based on no data\n",
    "heads_prob_nodata = get_heads_prob([])\n",
    "\n",
    "# Plot the distribution of heads probability with no data\n",
    "sns.kdeplot(heads_prob_nodata, shade=True, label=\"no data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc491508-b8cb-4575-a26a-8d1ab7398dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate and plot heads probability based on a single tails\n",
    "heads_prob_onetails = get_heads_prob([0])\n",
    "\n",
    "# Plot the distribution of heads probability with a single tails\n",
    "sns.kdeplot(heads_prob_onetails, shade=True, label=\"single tails\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f3b97-7ce8-4ccd-ac6f-21b637ad873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate and plot heads probability based on 1000 tosses with a biased coin\n",
    "biased_tosses = np.random.choice([0, 1], size=1000, p=[0.95, 0.05])\n",
    "\n",
    "# Estimate heads probability based on biased_tosses\n",
    "heads_prob_biased = get_heads_prob(biased_tosses)\n",
    "\n",
    "# Plot the distribution of heads probability with a biased coin\n",
    "sns.kdeplot(data=heads_prob_biased, shade=True, label=\"biased coin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968565f7-6536-4609-9f1b-58da9969d193",
   "metadata": {},
   "source": [
    "### Hey, is this coin fair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2268618-ee67-41cf-939a-7723f1126446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming tosses is already defined\n",
    "tosses_first_10 = tosses[:10]\n",
    "tosses_first_100 = tosses[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea47ad2-f8dc-45db-8eb6-9aec0554751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign first 10 and 100 tosses to separate variables\n",
    "tosses_first_10 = tosses[:10]\n",
    "tosses_first_100 = tosses[:100]\n",
    "\n",
    "# Get head probabilities for first 10, first 100, and all tossses\n",
    "heads_prob_first_10 = get_heads_prob(tosses_first_10)\n",
    "heads_prob_first_100 = get_heads_prob(tosses_first_100)\n",
    "heads_prob_all = get_heads_prob(tosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a007a-7698-401d-a9ec-1d1f0baabd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign first 10 and 100 tosses to separate variables\n",
    "tosses_first_10 = tosses[:10]\n",
    "tosses_first_100 = tosses[:100]\n",
    "\n",
    "# Get head probabilities for first 10, first 100, and all tossses\n",
    "heads_prob_first_10 = get_heads_prob(tosses_first_10)\n",
    "heads_prob_first_100 = get_heads_prob(tosses_first_100)\n",
    "heads_prob_all = get_heads_prob(tosses)\n",
    "\n",
    "\n",
    "# Plot density of head probability for the first 10 tosses\n",
    "sns.kdeplot(data=heads_prob_first_10, shade=True, label=\"first_10\")\n",
    "\n",
    "# Plot density of head probability for the first 100 tosses\n",
    "sns.kdeplot(data=heads_prob_first_100, shade=True, label=\"first_100\")\n",
    "\n",
    "# Plot density of head probability for all tosses\n",
    "sns.kdeplot(data=heads_prob_all, shade=True, label=\"all\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b8987-c23c-4ffe-8d2d-3f67d4a0b2cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759a78e-b415-4368-864e-ee7e42ffeda2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Towards grid approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51723b-d514-4e2e-9f01-f853416d6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of all possible numbers of patients cured (from 0 to 10)\n",
    "num_patients_cured = np.arange(11)\n",
    "\n",
    "# Create array of all possible values for the efficacy rate (from 0 to 1, by 0.01)\n",
    "efficacy_rate = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# Combine the two arrays in one DataFrame\n",
    "df = pd.DataFrame([(x, y) for x in num_patients_cured for y in efficacy_rate])\n",
    "\n",
    "# Name the columns\n",
    "df.columns = [\"num_patients_cured\", \"efficacy_rate\"]\n",
    "\n",
    "# Print df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3bd03f-3faa-42e8-8ad1-0fa9ef45ec05",
   "metadata": {},
   "source": [
    "## Grid approximation without prior knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ff436-2888-4c7f-b9c9-0c07e10fe5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the uniform prior for efficacy_rate\n",
    "df[\"prior\"] = uniform.pdf(df[\"efficacy_rate\"], loc=0, scale=1)\n",
    "\n",
    "# Calculate the binomial likelihood\n",
    "df[\"likelihood\"] = binom.pmf(df[\"num_patients_cured\"], n=10, p=df[\"efficacy_rate\"])\n",
    "\n",
    "# Print df with the new columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b348a-25c4-456b-91a8-ce358d4b8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the prior efficacy rate and the likelihood\n",
    "df[\"prior\"] = uniform.pdf(df[\"efficacy_rate\"])\n",
    "df[\"likelihood\"] = binom.pmf(df[\"num_patients_cured\"], 10, df[\"efficacy_rate\"])\n",
    "\n",
    "# Calculate the unnormalized posterior efficacy rate\n",
    "df[\"posterior_prob\"] = df[\"prior\"] * df[\"likelihood\"]\n",
    "\n",
    "# Scale the posterior probability to sum up to one\n",
    "df[\"posterior_prob\"] /= df[\"posterior_prob\"].sum()\n",
    "\n",
    "# Print df with the new columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103d559-53b8-4908-9d49-63a4f50db5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the prior efficacy rate and the likelihood\n",
    "df[\"prior\"] = uniform.pdf(df[\"efficacy_rate\"])\n",
    "df[\"likelihood\"] = binom.pmf(df[\"num_patients_cured\"], 10, df[\"efficacy_rate\"])\n",
    "\n",
    "# Calculate the posterior efficacy rate and scale it to sum up to one\n",
    "df[\"posterior_prob\"] = df[\"prior\"] * df[\"likelihood\"]\n",
    "df[\"posterior_prob\"] /= df[\"posterior_prob\"].sum()\n",
    "\n",
    "# Filter df to keep only rows where the number of patients cured is 9\n",
    "df_9_of_10_cured = df[df[\"num_patients_cured\"] == 9]\n",
    "\n",
    "# Scale the posterior probability to sum up to one for the filtered rows\n",
    "df_9_of_10_cured[\"posterior_prob\"] /= df_9_of_10_cured[\"posterior_prob\"].sum()\n",
    "\n",
    "# Print df_9_of_10_cured\n",
    "print(df_9_of_10_cured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaac426-7c0b-4f69-878b-70e8f13f99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the prior efficacy rate and the likelihood\n",
    "df[\"prior\"] = uniform.pdf(df[\"efficacy_rate\"])\n",
    "df[\"likelihood\"] = binom.pmf(df[\"num_patients_cured\"], 10, df[\"efficacy_rate\"])\n",
    "\n",
    "# Calculate the posterior efficacy rate and scale it to sum up to one\n",
    "df[\"posterior_prob\"] = df[\"prior\"] * df[\"likelihood\"]\n",
    "df[\"posterior_prob\"] /= df[\"posterior_prob\"].sum()\n",
    "\n",
    "# Compute the posterior probability of observing 9 cured patients\n",
    "df_9_of_10_cured = df.loc[df[\"num_patients_cured\"] == 9]\n",
    "df_9_of_10_cured[\"posterior_prob\"] /= df_9_of_10_cured[\"posterior_prob\"].sum()\n",
    "\n",
    "sns.lineplot(x=df_9_of_10_cured[\"efficacy_rate\"], y=df_9_of_10_cured[\"posterior_prob\"], label=\"Posterior Efficacy Rate\")\n",
    "\n",
    "plt.xlabel(\"efficacy_rate\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.title(\"Posterior Efficacy Rate after 9 out of 10 Patients Cured\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57035e86-1856-4d98-a577-bb18835bad27",
   "metadata": {},
   "source": [
    "### Updating posterior belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470abd61-810a-4863-abd8-1fdb9a506191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign old posterior to new prior and calculate likelihood\n",
    "df[\"new_prior\"] = df[\"posterior_prob\"]\n",
    "df[\"new_likelihood\"] = binom.pmf(df[\"num_patients_cured\"], 12, df[\"efficacy_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a9244-c8d3-4584-8600-e7f037d8defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign old posterior to new prior and calculate likelihood\n",
    "df[\"new_prior\"] = df[\"posterior_prob\"]\n",
    "df[\"new_likelihood\"] = binom.pmf(df[\"num_patients_cured\"], 12, df[\"efficacy_rate\"])\n",
    "\n",
    "# Calculate new posterior and scale it\n",
    "df[\"new_posterior_prob\"] = df[\"new_prior\"] * df[\"new_likelihood\"]\n",
    "df[\"new_posterior_prob\"] /= df[\"new_posterior_prob\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27724207-c647-45ac-8bb6-ab0aa311221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign old posterior to new prior and calculate likelihood\n",
    "df[\"new_prior\"] = df[\"posterior_prob\"]\n",
    "df[\"new_likelihood\"] = binom.pmf(df[\"num_patients_cured\"], 12, df[\"efficacy_rate\"])\n",
    "\n",
    "# Calculate new posterior and scale it\n",
    "df[\"new_posterior_prob\"] = df[\"new_prior\"] * df[\"new_likelihood\"]\n",
    "df[\"new_posterior_prob\"] /= df[\"new_posterior_prob\"].sum()\n",
    "\n",
    "# Compute the posterior probability of observing 10 cured patients\n",
    "df_10_of_12_cured = df[df[\"num_patients_cured\"] == 10].copy()\n",
    "df_10_of_12_cured[\"new_posterior_prob\"] /= df_10_of_12_cured[\"new_posterior_prob\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3babd28-53b3-4c81-b405-eb3076b7d382",
   "metadata": {},
   "source": [
    "### Simulating posterior draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e51c0b-ef4c-4871-ac6f-fa76b5bc9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of patients treated and cured\n",
    "num_patients_treated = 22\n",
    "num_patients_cured = 19\n",
    "\n",
    "# Simulate 10000 draws from the posterior distribution\n",
    "posterior_draws = np.random.beta(5 + num_patients_cured, 2 + num_patients_treated - num_patients_cured, 10000)\n",
    "\n",
    "# Plot the posterior distribution using sns.kdeplot()\n",
    "sns.kdeplot(posterior_draws, shade=True, label=\"Posterior Distribution\")\n",
    "plt.xlabel(\"Efficacy Rate\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Posterior Distribution of Efficacy Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa439ad-4e79-404e-b98e-22a394d78955",
   "metadata": {},
   "source": [
    "### Point estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7889d-c732-4fce-a4d4-b21f32ab411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the expected number of people cured\n",
    "cured_expected = np.mean(drug_efficacy_posterior_draws) * 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a8141-20cb-4386-bc29-689e37169f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the expected number of people cured\n",
    "cured_expected = np.mean(drug_efficacy_posterior_draws) * 100_000\n",
    "\n",
    "# Calculate the minimum number of people cured with 50% probability\n",
    "min_cured_50_perc = np.percentile(drug_efficacy_posterior_draws, 50) * 100_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73079a5f-e36f-40a6-a6b0-004cfc023eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the expected number of people cured\n",
    "cured_expected = np.mean(drug_efficacy_posterior_draws) * 100_000\n",
    "\n",
    "# Calculate the minimum number of people cured with 50% probability\n",
    "min_cured_50_perc = np.median(drug_efficacy_posterior_draws) * 100_000\n",
    "\n",
    "# Calculate the minimum number of people cured with 90% probability\n",
    "min_cured_90_perc = np.percentile(drug_efficacy_posterior_draws, 10) * 100_000\n",
    "\n",
    "\n",
    "# Print the filled-in memo\n",
    "print(f\"Based on the experiments carried out by ourselves and neighboring countries, \\nshould we distribute the drug, we can expect {int(cured_expected)} infected people to be cured. \\nThere is a 50% probability the number of cured infections \\nwill amount to at least {int(min_cured_50_perc)}, and with 90% probability \\nit will not be less than {int(min_cured_90_perc)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42915129-e91d-49c4-b3fe-fb15b75d5375",
   "metadata": {},
   "source": [
    "### Highest Posterior Density credible intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02bb4d-3ce1-4849-9eae-0a02a4af5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate HPD credible interval of 90%\n",
    "ci_90 = np.percentile(drug_efficacy_posterior_draws, [5, 95])\n",
    "\n",
    "# Calculate HPD credible interval of 95%\n",
    "ci_95 = np.percentile(drug_efficacy_posterior_draws, [2.5, 97.5])\n",
    "\n",
    "# Print the memo\n",
    "print(f\"The experimental results indicate that with a 90% probability \\nthe new drug's efficacy rate is between {np.round(ci_90[0], 2)} and {np.round(ci_90[1], 2)}, \\nand with a 95% probability it is between {np.round(ci_95[0], 2)} and {np.round(ci_95[1], 2)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d275f-f5cf-41a7-9cd9-1ef0b6cba957",
   "metadata": {},
   "source": [
    "### Simulate beta posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870c00d-3bac-4c4f-8162-42bc3bc76d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set prior parameters and calculate number of successes\n",
    "beta_prior_a = 1\n",
    "beta_prior_b = 1\n",
    "num_successes = np.sum(tosses)\n",
    "\n",
    "# Generate 10000 posterior draws\n",
    "posterior_draws = np.random.beta(\n",
    "    beta_prior_a + num_successes,\n",
    "    beta_prior_b + len(tosses) - num_successes,\n",
    "    10000\n",
    ")\n",
    "\n",
    "# Plot density of posterior_draws\n",
    "sns.kdeplot(posterior_draws, shade=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04245108-7227-4cf0-93b7-4518027832b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prior parameters and calculate number of successes\n",
    "beta_prior_a = 1\n",
    "beta_prior_b = 10\n",
    "num_successes = np.sum(tosses)\n",
    "\n",
    "# Generate 10000 posterior draws\n",
    "posterior_draws = np.random.beta(\n",
    "    beta_prior_a + num_successes,\n",
    "    beta_prior_b + len(tosses) - num_successes,\n",
    "    10000\n",
    ")\n",
    "\n",
    "# Plot density of posterior_draws\n",
    "sns.kdeplot(posterior_draws, shade=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d35c05-534f-44f8-91c3-be360ee92d30",
   "metadata": {},
   "source": [
    "### Posterior click rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2565b-c963-480c-ae55-ace95f3e4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prior draws\n",
    "prior_draws = np.random.beta(10, 50, 100000)\n",
    "\n",
    "# Plot the prior\n",
    "sns.kdeplot(prior_draws, shade=True, label=\"prior\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9b03c-132f-48a8-a1c5-e5846cd2c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prior draws\n",
    "prior_draws = np.random.beta(10, 50, 100000)\n",
    "\n",
    "# Plot the prior\n",
    "sns.kdeplot(prior_draws, shade=True, label=\"prior\")\n",
    "plt.show()\n",
    "\n",
    "# Extract the banner_clicked column for each product\n",
    "clothes_clicked = ads.loc[ads['product'] == 'clothes']['banner_clicked']\n",
    "sneakers_clicked = ads.loc[ads['product'] == 'sneakers']['banner_clicked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b4242-ac51-44c8-8a40-1ed9b40b7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prior draws\n",
    "prior_draws = np.random.beta(10, 50, 100000)\n",
    "\n",
    "# Plot the prior\n",
    "sns.kdeplot(prior_draws, shade=True, label=\"prior\")\n",
    "plt.show()\n",
    "\n",
    "# Extract the banner_clicked column for each product\n",
    "clothes_clicked = ads.loc[ads[\"product\"] == \"clothes\"][\"banner_clicked\"]\n",
    "sneakers_clicked = ads.loc[ads[\"product\"] == \"sneakers\"][\"banner_clicked\"]\n",
    "\n",
    "# Simulate posterior draws for each product\n",
    "clothes_posterior = simulate_beta_posterior(clothes_clicked, 10, 50)\n",
    "sneakers_posterior = simulate_beta_posterior(sneakers_clicked, 10, 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f672cdd-fe80-4487-ba12-dc5b51ff23a8",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a52c1f-417b-49ae-a453-478f09d7c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate posterior difference\n",
    "diff = clothes_posterior - sneakers_posterior\n",
    "\n",
    "# Plot the posterior difference\n",
    "sns.kdeplot(diff, shade=True, label=\"diff\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeee92d-733b-4b8d-90ad-34d2ad3fb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate posterior difference and plot it\n",
    "diff = clothes_posterior - sneakers_posterior\n",
    "sns.kdeplot(diff, shade=True, label=\"diff\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate 90% HPD credible interval of posterior difference\n",
    "interval = az.hdi(diff, hdi_prob=0.9)\n",
    "\n",
    "# Print the interval\n",
    "print(interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dae526-8df2-4fb8-be61-1a0dcb96515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate posterior difference and plot it\n",
    "diff = clothes_posterior - sneakers_posterior\n",
    "sns.kdeplot(diff, shade=True, label=\"diff\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print 90% credible interval of posterior difference\n",
    "interval = az.hdi(diff, hdi_prob=0.9)\n",
    "print(interval)\n",
    "\n",
    "# Calculate and print probability of clothes ad being better\n",
    "clothes_better_prob = np.mean(diff > 0)\n",
    "print(clothes_better_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8e7b4-2131-4547-a9b7-4fb88f8f2a4e",
   "metadata": {},
   "source": [
    "### How bad can it be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf75afa-6ff2-4583-9de7-9b20795d3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice diff to take only cases where it is negative\n",
    "loss = diff[diff < 0]\n",
    "\n",
    "# Compute and print expected loss\n",
    "expected_loss = np.mean(loss)\n",
    "print(expected_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16fbe19-f667-4567-97b0-2bd0fc89e755",
   "metadata": {},
   "source": [
    "### Decision analysis: cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d05e3-b5d2-46da-8773-60f904073a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distributions of the numbers of clicks for clothes and sneakers\n",
    "clothes_num_clicks = clothes_posterior * 10000\n",
    "sneakers_num_clicks = sneakers_posterior * 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fb073-cef1-4cda-84a9-d0506a7c88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distributions of the numbers of clicks for clothes and sneakers\n",
    "clothes_num_clicks = clothes_posterior * 10_000\n",
    "sneakers_num_clicks = sneakers_posterior * 10_000\n",
    "\n",
    "# Calculate cost distributions for each product and platform\n",
    "ads_costs = {\n",
    "    \"clothes_mobile\": clothes_num_clicks * 2.5,\n",
    "    \"sneakers_mobile\": sneakers_num_clicks * 2.5,\n",
    "    \"clothes_desktop\": clothes_num_clicks * 2,\n",
    "    \"sneakers_desktop\": sneakers_num_clicks * 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3becc6a-9c79-496a-8400-3f92ff88485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distributions of the numbers of clicks for clothes and sneakers\n",
    "clothes_num_clicks = clothes_posterior * 10_000\n",
    "sneakers_num_clicks = sneakers_posterior * 10_000\n",
    "\n",
    "# Calculate cost distributions for each product and platform\n",
    "ads_costs = {\n",
    "    \"clothes_mobile\": clothes_num_clicks * 2.5,\n",
    "    \"sneakers_mobile\": sneakers_num_clicks * 2.5,\n",
    "    \"clothes_desktop\": clothes_num_clicks * 2,\n",
    "    \"sneakers_desktop\": sneakers_num_clicks * 2,\n",
    "}\n",
    "\n",
    "# Draw a forest plot of ads_costs\n",
    "pm.forestplot(ads_costs, hdi_prob=0.99, textsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6cd0c-c01f-405c-a20b-51b17e33f539",
   "metadata": {},
   "source": [
    "### Decision analysis: profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad771d8-b909-484d-b4e8-52abb7bfe627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate profit distributions for each product and platform\n",
    "ads_profit = {\n",
    "    \"clothes_mobile\": (clothes_num_clicks * 3.4) - ads_costs[\"clothes_mobile\"],\n",
    "    \"sneakers_mobile\": (sneakers_num_clicks * 3.4) - ads_costs[\"sneakers_mobile\"],\n",
    "    \"clothes_desktop\": (clothes_num_clicks * 3) - ads_costs[\"clothes_desktop\"],\n",
    "    \"sneakers_desktop\": (sneakers_num_clicks * 3) - ads_costs[\"sneakers_desktop\"],\n",
    "}\n",
    "\n",
    "# Draw a forest plot of ads_profit\n",
    "pm.forestplot(ads_profit, hdi_prob=0.99, textsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66db34-5fda-4bbe-9e67-1f98e52265a8",
   "metadata": {},
   "source": [
    "### Analyzing regression parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09562e9d-4c50-46b4-b689-5dea81cf7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect parameter draws in a DataFrame\n",
    "posterior_draws_df = pd.DataFrame({\n",
    "    \"intercept_draws\": intercept_draws,\n",
    "    \"clothes_draws\": clothes_draws,\n",
    "    \"sneakers_draws\": sneakers_draws,\n",
    "    \"sd_draws\": sd_draws,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb9987-9510-4415-b640-5bbb2dd2d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect parameter draws in a DataFrame\n",
    "posterior_draws_df = pd.DataFrame({\n",
    "    \"intercept_draws\": intercept_draws,\n",
    "    \"clothes_draws\": clothes_draws,\n",
    "  \t\"sneakers_draws\": sneakers_draws,\n",
    "    \"sd_draws\": sd_draws,\n",
    "})\n",
    "\n",
    "# Describe parameter posteriors\n",
    "draws_stats = posterior_draws_df.describe()\n",
    "print(draws_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095464b2-2370-4ebf-b318-233301620320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect parameter draws in a DataFrame\n",
    "posterior_draws_df = pd.DataFrame({\n",
    "    \"intercept_draws\": intercept_draws,\n",
    "    \"clothes_draws\": clothes_draws,\n",
    "  \t\"sneakers_draws\": sneakers_draws,\n",
    "    \"sd_draws\": sd_draws,\n",
    "})\n",
    "\n",
    "# Describe parameter posteriors\n",
    "draws_stats = posterior_draws_df.describe()\n",
    "print(draws_stats)\n",
    "\n",
    "# Plot clothes parameter posterior\n",
    "pm.plot_posterior(clothes_draws, hdi_prob=0.99)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083f5ef-d853-4ab7-b71b-01f052aac017",
   "metadata": {},
   "source": [
    "### Predictive distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adab384-0576-4a04-9d87-5cbb650f2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate posteriors of the parameters to point estimates\n",
    "intercept_coef = intercept_draws.mean()\n",
    "sneakers_coef = sneakers_draws.mean()\n",
    "clothes_coef = clothes_draws.mean()\n",
    "sd_coef = sd_draws.mean()\n",
    "\n",
    "print(\"Posterior Mean of Intercept:\", intercept_coef)\n",
    "print(\"Posterior Mean of Sneakers Coef:\", sneakers_coef)\n",
    "print(\"Posterior Mean of Clothes Coef:\", clothes_coef)\n",
    "print(\"Posterior Mean of SD Coef:\", sd_coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a03e5b-100c-4e76-970b-316694438b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate posteriors of the parameters to point estimates\n",
    "intercept_coef = np.mean(intercept_draws)\n",
    "sneakers_coef = np.mean(sneakers_draws)\n",
    "clothes_coef = np.mean(clothes_draws)\n",
    "sd_coef = np.mean(sd_draws)\n",
    "\n",
    "# Calculate the mean of the predictive distribution\n",
    "pred_mean = intercept_coef + 10 * sneakers_coef + 10 * clothes_coef\n",
    "\n",
    "print(\"Mean of the Predictive Distribution:\", pred_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac73b7c-7998-48e6-84e6-93a4cce7c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate posteriors of the parameters to point estimates\n",
    "intercept_coef = np.mean(intercept_draws)\n",
    "sneakers_coef = np.mean(sneakers_draws)\n",
    "clothes_coef = np.mean(clothes_draws)\n",
    "sd_coef = np.mean(sd_draws)\n",
    "\n",
    "# Calculate the mean of the predictive distribution\n",
    "pred_mean = intercept_coef + sneakers_coef * 10 + clothes_coef * 10\n",
    "\n",
    "# Sample 1000 draws from the predictive distribution\n",
    "pred_draws = np.random.normal(loc=pred_mean, scale=sd_coef, size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1f89d-a282-4bc8-83f9-e03e903eb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate posteriors of the parameters to point estimates\n",
    "intercept_coef = np.mean(intercept_draws)\n",
    "sneakers_coef = np.mean(sneakers_draws)\n",
    "clothes_coef = np.mean(clothes_draws)\n",
    "sd_coef = np.mean(sd_draws)\n",
    "\n",
    "# Calculate the mean of the predictive distribution\n",
    "pred_mean = intercept_coef + sneakers_coef * 10 + clothes_coef * 10\n",
    "\n",
    "# Sample 1000 draws from the predictive distribution\n",
    "pred_draws = np.random.normal(pred_mean, sd_coef, size=1000)\n",
    "\n",
    "# Plot the density of the predictive distribution\n",
    "pm.plot_posterior(pred_draws, hdi_prob=0.99)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee08289f-8799-4e39-8914-9a7d0881aa11",
   "metadata": {},
   "source": [
    "### Inspecting posterior draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff0b5e-5c34-4688-a645-bf33b3835f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pymc3\n",
    "import pymc3 as pm\n",
    "\n",
    "# Draw a trace plot of trace_1\n",
    "pm.traceplot(trace_1)\n",
    "plt.show()\n",
    "\n",
    "# Draw a forest plot of trace_1\n",
    "pm.forestplot(trace_1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970e7d1-b8a9-45cc-bf62-0fa8b804d746",
   "metadata": {},
   "source": [
    "### Comparing models with WAIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8eea44-d0e2-4d44-9d01-a8af07635ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather trace_1 and trace_2 into a dictionary\n",
    "traces_dict = {'trace_1': trace_1, 'trace_2': trace_2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6cde5-71f2-4820-8f17-1f6fd3924034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather trace_1 and trace_2 into a dictionary\n",
    "traces_dict = {\"trace_1\": trace_1, \"trace_2\": trace_2}\n",
    "\n",
    "# Create a comparison table based on WAIC\n",
    "comparison = pm.compare(traces_dict, ic='waic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab662d-41f3-49cc-8d98-43f77f02bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather trace_1 and trace_2 into a dictionary\n",
    "traces_dict = {\"trace_1\": trace_1, \"trace_2\": trace_2}\n",
    "\n",
    "# Create a comparison table based on WAIC\n",
    "comparison = pm.compare(traces_dict, ic=\"waic\")\n",
    "\n",
    "# Draw a comparison plot\n",
    "pm.compareplot(comparison, textsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ec2dd-e3c6-4120-ae60-f4b82862526f",
   "metadata": {},
   "source": [
    "### Sample from predictive density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3f5dc-09ed-494e-9002-b79947ec3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print bikes_test head\n",
    "print(bikes_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2bc28-32f2-4e68-a83f-b666a4959eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print bikes_test head\n",
    "print(bikes_test.head())\n",
    "\n",
    "# Define the formula\n",
    "formula = \"num_bikes ~ temp + work_day + wind_speed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e56e45-3a47-439a-936f-6f5274cbe4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print bikes_test head\n",
    "print(bikes_test.head())\n",
    "\n",
    "# Define the formula\n",
    "formula = \"num_bikes ~ temp + work_day + wind_speed\"\n",
    "\n",
    "# Generate predictive draws\n",
    "with pm.Model() as model:\n",
    "    pm.GLM.from_formula(formula, data=bikes_test)\n",
    "    posterior_predictive = pm.fast_sample_posterior_predictive(trace_2, samples=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90ce46-6f76-4b76-9a4a-830a28848bb4",
   "metadata": {},
   "source": [
    "### Estimating test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0718d1a-758c-42a3-a4dc-4991e1863d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize errors\n",
    "errors = []\n",
    "\n",
    "# Iterate over rows of bikes_test to compute error per row\n",
    "for index, test_example in bikes_test.iterrows():\n",
    "    error = posterior_predictive[\"y\"][:, index] - test_example[\"num_bikes\"]\n",
    "    errors.append(error)\n",
    "\n",
    "# Reshape errors\n",
    "error_distribution = np.array(errors).reshape(-1)\n",
    "\n",
    "# Plot the error distribution\n",
    "pm.plot_posterior(error_distribution, textsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007e770-1ba1-431e-922f-5b6785032950",
   "metadata": {},
   "source": [
    "### Inspecting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34540d5c-0e2b-42bd-a290-00a6c050732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a trace plot of trace\n",
    "pm.traceplot(trace)\n",
    "plt.show()\n",
    "\n",
    "# Print a summary of trace\n",
    "summary = pm.summary(trace)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a56ac3-4e2c-400b-8280-2b67884a5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a trace plot of trace\n",
    "pm.traceplot(trace)\n",
    "plt.show()\n",
    "\n",
    "# Print a summary of trace\n",
    "summary = pm.summary(trace)\n",
    "print(summary)\n",
    "\n",
    "# Get each parameter's posterior mean\n",
    "intercept_mean = np.mean(trace.get_values('Intercept'))\n",
    "organic_mean = np.mean(trace.get_values('type_organic'))\n",
    "price_mean = np.mean(trace.get_values('price'))\n",
    "sd_mean = np.mean(trace.get_values('sd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69e9a2-7fa2-4aaf-bf58-2e4a12cbb0b7",
   "metadata": {},
   "source": [
    "### Optimizing the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01906d-bd89-4129-a3ad-43618e90df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each price, predict volume and use it to predict profit\n",
    "predicted_profit_per_price = {}\n",
    "for price in [0.5, 0.75, 1, 1.25]:\n",
    "    pred_mean = (intercept_mean + price_mean * price + organic_mean)\n",
    "    volume_pred = np.random.normal(pred_mean, sd_mean, size=1000)\n",
    "    profit_pred = price * volume_pred\n",
    "    predicted_profit_per_price.update({price: profit_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef0fbf-8232-4e89-8ec5-2a4bf3deb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each price, predict volume and use it to predict profit\n",
    "predicted_profit_per_price = {}\n",
    "for price in [0.5, 0.75, 1, 1.25]:\n",
    "    pred_mean = (intercept_mean + price_mean * price + organic_mean)\n",
    "    volume_pred = np.random.normal(pred_mean, sd_mean, size=1000)\n",
    "    profit_pred = price * volume_pred\n",
    "    predicted_profit_per_price.update({price: profit_pred})\n",
    "    \n",
    "# Draw a forest plot of predicted profit for all prices\n",
    "pm.forestplot(predicted_profit_per_price)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becb306-97a7-4065-bcba-62495ff4ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each price, predict volume and use it to predict profit\n",
    "predicted_profit_per_price = {}\n",
    "for price in [0.5, 0.75, 1, 1.25]:\n",
    "    pred_mean = (intercept_mean + price_mean * price + organic_mean)\n",
    "    volume_pred = np.random.normal(pred_mean, sd_mean, size=1000)\n",
    "    profit_pred = price * volume_pred\n",
    "    predicted_profit_per_price.update({price: profit_pred})\n",
    "    \n",
    "# Draw a forest plot of predicted profit for all prices\n",
    "pm.forestplot(predicted_profit_per_price)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print HPD of predicted profit for the optimal price\n",
    "opt_hpd = az.hdi(predicted_profit_per_price[0.75], credible_interval=0.99)\n",
    "print(opt_hpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9adc15b-3fba-4a21-b66c-5ae7db46388d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d696c24-f3fb-4f74-aa96-581d0e07429d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b1ed0-4e66-46ba-a656-341dd7913dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0afb2-050d-406d-9b3a-8b7d789e5990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
